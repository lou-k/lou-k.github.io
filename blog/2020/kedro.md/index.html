<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Lou Kratz | Kedro 6 Months In</title>
  <meta name="description" content="Lou Kratz is a research engineer who specializes in computer vision and machine learning.
">

  <link rel="shortcut icon" href="https://lou.dev/assets/img/favicon.ico">

  <link rel="stylesheet" href="https://lou.dev/assets/css/main.css">
  <link rel="canonical" href="https://lou.dev/blog/2020/kedro.md/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Lou</strong> Kratz
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="https://lou.dev/">about</a>

        <!-- Blog -->
        <a class="page-link" href="https://lou.dev/blog/">blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="https://lou.dev/publications/">publications</a>
          
        
          
            <a class="page-link" href="https://lou.dev/talks/">talks</a>
          
        
          
            <a class="page-link" href="https://lou.dev/teaching/">teaching</a>
          
        
          
        
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="https://lou.dev/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Kedro 6 Months In</h1>
    <p class="post-meta">November 6, 2020</p>
  </header>

  <article class="post-content">
    I build AI software in two modes: experimentation and productization. During experimentation, I am trying to see _if_ modern technology will solve my problem. If it does, 
I move on to productization and build reliable data pipelines at scale.

This presents a cyclical dependency when it comes to data engineering, however: I need reliable, maintainable data engineering pipelines during experimentation, but I don't know _what_ that pipeline should do until I've completed my experiments. 
In the past I, and many data scientists I know, have just used an _ad-hoc_ combination of bash scripts and jupyter notebooks wrangling experimental data.
While this may have been the fastest way to get experimental results and model building, it's really a tech debt that has to be paid down the road.

# The Problem

Specifically, the ad-hoc approach to experimental data pipelines causes pain points around:

* **Reproducibility**: Ad-hoc experimentation structures puts you at risk of making results that others can't produce, which can lead to product down time if/when you need to update your approach. Simple mistakes like executing a notebook cell twice, or forgetting to seed a random number generator can usually be caught. But other, more difficult problems can occur, such as behavior changes between dependency versions.
* **Readability**: If you've ever come across another person's experimental code, you know it's hard to find where to start. Even documented projects might just say "run x script, y notebook, etc", and it's often unclear where the data come from and if you're on the right track.  Similarly, code reviews for data science projects are often hard to read: it's often asking a lot for a reader to differentiate notebook code that is for data manipulation or just visualization.
* **Maintainability**: It's common during data science projects to do some exploritory analysis or generate early results, and then revise how your data is processed or gathered. This becomes difficult and tedious when all of these steps are an unstructured collection of notebooks or scripts. In other words, the pipeline is hard to maintain: updating or changing it requires you to keep track of the whole thing. 
* **Sharability**:  Ad-hoc collections of notebooks and bash scripts are also difficult for a team to work on concurrently. Each member had to ensure their notebooks were up-to-date (version control on notebooks is less than ideal), and that they had the correct copy of any intermediate data.

# Enter Kedro


A lot of the issues above aren't new to software engineering disciplines and have been largely solved in that space. 
This is where [Kedro](https://kedro.readthedocs.io/en/stable/) comes in. Kedro is a framework for building data-engineering pipelines whose structure forces you to follow good software engineering practices.
By using kedro in the experimentation phase of projects, we can build maintainable and reproducible data pipelines that produce consistent experimental results.

Specifically, kedro has you organize your data engineering code into one or more _pipelines_. Each pipeline consist of a number of _nodes_: a functional unit that takes some data sets and parameters as inputs and produces new data sets. 

This simple but strict project structure is augmented by their [_data catalog_](https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html): a yaml file that specifies how and where the input and output data sets are to be persisted to either disk or a cloud data storage service such as S3.

I started using kedro about six months ago, and since then have leveraged it for forr different experimental data pipelines. Some of these pipelines were for building models that eventually were deployed to production, and some were collaborations with team memebers. Below, I'll discuss the good and bad things I've found with kedro and how it helped us create reproducible, maintainable data pipleines.


## The Good

* **Reproducibility**: I can't say enough good things here: they nailed it. Their dependency management took a bit getting used to but it forces a specific version of all dependencies, which is awesome. Also, the ability to just type `kedro install` and `kedro run` to execute the whole pipeline is fantastic. You still have to remember to seed random number generators, but even that is easy to rememebr if you put it in their `params.yml` file.
* **Function Isolation**: Kedro's fixed project structure encourages you to think about what logical steps are necessary for your pipeline, and write a single node for each step. As a result, each node tends to be short (in terms of lines of code) and specific (in terms of logic). This makes each node easy to write, test, and read later on.
* **Developer Parallelization**: The small nodes also make it easier for developers to work togethger concurrently. It's often easy to spot nodes that won't depend on each other, and they can be coded concurrenty by different people.
* **Intermediate Data**: Perhaps my favorite thing about Kedro is the data catlog: just add the name of an output data set to `catalog.yml` and BOOM, it'll be serialized to disk or your cloud data store. This makes it super easy to build up the pipeline: you work on one node, commit it, execute it, and save the results. It also comes in handy when working on a team: I can run an expensive node on a big GPU machine and save the results to s3, and another team memeber can simply start from there. It's all baked in.
* **Code Reusability**:  I'll admit I have _never_ re-used a notebook. At best I pulled up an old one to remind myself how I achieved some complex analysis, but even then I had to remember the intricices of the data. The isolation of nodes, however, make it easy to re-use them. Also, Kedro's support for [modular pipelines](https://kedro.readthedocs.io/en/stable/06_nodes_and_pipelines/02_pipelines.html#developing-modular-pipelines) (i.e., packaging a pipeline into a pip package) makes it simple to share common code. We've even started publishing repos pipelines we use for common tasks such as image processing.

## The Bad
While kedro has solved many of the quality challenges in experiemtnal data pipelines, we have noticed a few gotchas that required less than elegant work arounds:
* **Incremental Dataset** support exists for reading data, but it's lacking for writing datasets. This hit us a few times when we had a node that would take 8-10 hours to run. If it fails part of the way through, we lost the work since it wasn't serialized until the end. Similarly, if the result dataset won't fit in memory, there wasn't a good way to save partial results since the intermediate data set writer in kedro assumes all data in is in memory. [This github issue](https://github.com/quantumblacklabs/kedro/issues/499) may fix it, if the developers address it, but for now you have to manage partial results on your own.
* **Pipeline Growth**. Pipelines can quickly get hard to follow since the input and outputs are just named variables that may or may not exist in the data catalog. [Kedro Viz](https://github.com/quantumblacklabs/kedro-viz) helps with this, but it's a bit annoying to switch between the navigator and code. We've also started enforcing name consistency between the node names and their functions, as well as the dataset names in the pipeline and the argument names in the node fucntions. Finally, making more, smaller pipelines is also a good way to keep your sanity. While all of these techniques help you to mentally keep track, it's still the trade off you make for coding the pipelines by naming the inputs and outputs.
* **Visulation** isn't really considered much in kedro, and is the one thing I'd say notebooks still have a leg up on. Kedro makes it easy for you to load the kedro context in a notebook, however, so you can still fire one up to do some visualization. Ultimately, however, I'd love to see better support within kedro for producing a graphical report that gets persisted to the `08_reporting` layer. Right now we worked around this by making a node that renders a nodebook to disk, but it's a  hack at best. I'd love better support for generating a final, data-driven reports that can be versioned in the data catalog much like the intermediate data.

# Conclusion

So am I a kedro convert? You betcha. It's replaced the spider-web of bash scripts and python notebooks I used to use for my experimental data pipelines and model training, and enabled better collaboration among our teams.
It won't replace a fully productionized stream-based data pipeline for me, but it absoluletly makes sure my experimental pipelines are maintainable, reproducable, and shareable.

  </article>

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2020 Lou Kratz.
    
    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="https://lou.dev/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="https://lou.dev/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://lou.dev/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="https://lou.dev/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-124061948-1', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
